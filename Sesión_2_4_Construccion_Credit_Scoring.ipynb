{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpantojaj/Backtesting_Stresstesting/blob/main/Sesi%C3%B3n_2_4_Construccion_Credit_Scoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb9GMvxs8XyX"
      },
      "source": [
        "#**Desarrollo de un Modelo de Credit Scoring**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaTDbaE0EB0t"
      },
      "source": [
        "### **1. Carga Inicial de Librerías**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KU-3utxt_UlG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW354ETwEH4t"
      },
      "source": [
        "### **2. Entendimiento y Analisis Exploratorio de datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPdgJZ0B_vwO"
      },
      "outputs": [],
      "source": [
        "df_clase = pd.read_csv('Base_SolicitudesCreditoEfectivo_201307_201505.csv', sep = \";\")\n",
        "df_clase.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bY_v-0h847P"
      },
      "outputs": [],
      "source": [
        "df_clase.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKZi7pT49RkE"
      },
      "outputs": [],
      "source": [
        "df_clase.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPK10PlJ_0JE"
      },
      "outputs": [],
      "source": [
        "df_clase.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFtncrtxNle6"
      },
      "outputs": [],
      "source": [
        "df_clase['CODMES']=df_clase['CODMES'].astype(str)\n",
        "df_clase['CODSOLICITUD']=df_clase['CODSOLICITUD'].astype(str)\n",
        "df_clase['MIN_MES_DE_DEFAULT']=df_clase['MIN_MES_DE_DEFAULT'].astype(str)\n",
        "df_clase['FLG_GARANTIA']=df_clase['FLG_GARANTIA'].astype(str)\n",
        "df_clase['TARJETA_RELACIONADA']=df_clase['TARJETA_RELACIONADA'].astype(str)\n",
        "df_clase['VEHICULAR_RELACIONADA']=df_clase['VEHICULAR_RELACIONADA'].astype(str)\n",
        "df_clase['HIPOTECARIO_RELACIONADA']=df_clase['HIPOTECARIO_RELACIONADA'].astype(str)\n",
        "df_clase['CLASIF_SISTEMA_ULT_12M']=df_clase['CLASIF_SISTEMA_ULT_12M'].astype(str)\n",
        "df_clase['FLG_PDH']=df_clase['FLG_PDH'].astype(str)\n",
        "df_clase['FLG_TC_VISA']=df_clase['FLG_TC_VISA'].astype(str)\n",
        "df_clase['FLG_TC_MC']=df_clase['FLG_TC_MC'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMaddPEpWYJn"
      },
      "outputs": [],
      "source": [
        "df_clase.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2sAYMEkO8Zg"
      },
      "outputs": [],
      "source": [
        "df_clase.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGULk_uwR5YO"
      },
      "outputs": [],
      "source": [
        "target_count = df_clase['FLG_DEFAULT_12M'].value_counts()\n",
        "target_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0J4-Sy1E4it"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data = df_clase, x = \"FLG_DEFAULT_12M\", hue=\"FLG_DEFAULT_12M\")\n",
        "target_count = df_clase.FLG_DEFAULT_12M.value_counts()\n",
        "print('# Buen_Pagador:', target_count[0])\n",
        "print('# 1 Mora_12M:', target_count[1])\n",
        "print('Bad rate:', target_count[1]/(target_count[0]+target_count[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVKdulyXMG_G"
      },
      "outputs": [],
      "source": [
        "a1=df_clase.pivot_table(values=\"CODSOLICITUD\", index=\"CODMES\", aggfunc=\"count\", sort=True)\n",
        "a1.plot(kind = 'bar',\n",
        "       #stacked = 'True',          # Muestra las barras apiladas\n",
        "       alpha = 0.4,               # nivel de transparencia\n",
        "       width = 0.9,               # Grosor de las barras para dejar espacio entre ellas\n",
        "       figsize=(9,4));            # Cambiamos el tamaño de la figura"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8u313H-zO2eA"
      },
      "outputs": [],
      "source": [
        "a2=df_clase.pivot_table(values=\"FLG_DEFAULT_12M\", index=\"CODMES\", aggfunc=\"mean\", sort=True)\n",
        "a2.plot(alpha = 0.4, figsize=(9,4), ylim=(0.05,0.08))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hagamos el Análisis Univariado***"
      ],
      "metadata": {
        "id": "wCcaFoD-0Izx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Revisemos la cantidad de nulos y sus proporciones por variable"
      ],
      "metadata": {
        "id": "8ZD63VmY0S97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "null_values = pd.concat([df_clase.isnull().sum(), df_clase.isnull().sum() / len(df_clase)], axis = 1)\n",
        "null_values.rename(columns = {0: 'number_null_values',1: 'ratio_null_values'}, inplace = True)\n",
        "null_values"
      ],
      "metadata": {
        "id": "sdFtcJK50Fiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Revisemos sus estadísticos básicos"
      ],
      "metadata": {
        "id": "jTgsAztR0i_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clase.select_dtypes(include=['number']).describe().transpose()"
      ],
      "metadata": {
        "id": "KxMvH45I0iIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clase.select_dtypes(include=['object']).describe().transpose()"
      ],
      "metadata": {
        "id": "JoftO2O50Fge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Revisemos como se distribuye cada variable"
      ],
      "metadata": {
        "id": "ZXnXXaS905zQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clase.drop(columns = ['FLG_DEFAULT_12M']).hist(figsize = (12, 12))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v9dF2Gi00FeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clase.drop(columns = ['FLG_DEFAULT_12M']).boxplot(figsize = (20, 12))\n",
        "plt.yscale('log')\n",
        "plt.xticks(rotation = 45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P-M4Mp_l0FcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def outliers_col(df):\n",
        "  for columna in df:\n",
        "    if df[columna].dtype != object:\n",
        "      q1 = stats.scoreatpercentile(df[columna], 25)\n",
        "      q3 = stats.scoreatpercentile(df[columna], 75)\n",
        "      iqr = q3-q1\n",
        "      lim_inf = q1-1.5*iqr\n",
        "      lim_sup = q3+1.5*iqr\n",
        "      n_outliers_inf = len(df[(df[columna]<lim_inf)])\n",
        "      n_outliers_sup = len(df[(df[columna]>lim_sup)])\n",
        "      print(\"{} | {} | {}\".format(\n",
        "          df[columna].name,\n",
        "          n_outliers_inf,\n",
        "          n_outliers_sup\n",
        "          ))"
      ],
      "metadata": {
        "id": "CC3ronaq0FYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outliers_col(df_clase)"
      ],
      "metadata": {
        "id": "kbu2q5Yv0FVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljoht83fc2s3"
      },
      "source": [
        "# **3. Feature Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNRxdUhPc_eZ"
      },
      "source": [
        "#### 3.1 Tratamiento de Missing:\n",
        "####Según el caso elegiremos rellenar estos casos con un valor usualmente conocido (dado el tipo de variable que estemos analizando), o imputar con la mediana o el valor más frecuente, según sea numérica o categórica respectivamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0pfVxKJc1wZ"
      },
      "outputs": [],
      "source": [
        "# Para partir las bases\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf-bceoDepVC"
      },
      "outputs": [],
      "source": [
        "pip install feature_engine"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Partición Train y test (considerando estratificación de la Y)"
      ],
      "metadata": {
        "id": "eqggNz7CmRVi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-8Le4wrfZZV"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_clase.drop(\"FLG_DEFAULT_12M\", axis=1),\n",
        "    df_clase[\"FLG_DEFAULT_12M\"],\n",
        "    test_size=0.3,\n",
        "    random_state=0,\n",
        "    stratify=df_clase[\"FLG_DEFAULT_12M\"] #este punto es importante para asegurar un adecuado muestreo de la variable objetivo\n",
        ")\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQWpXwZigB8P"
      },
      "outputs": [],
      "source": [
        "# Comprobación de la proporción de Y en train\n",
        "y_train.value_counts()[1]/(y_train.value_counts()[0]+y_train.value_counts()[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwXhSV03gq-p"
      },
      "outputs": [],
      "source": [
        "# Comprobación de la proporción de Y en test\n",
        "y_test.value_counts()[1]/(y_test.value_counts()[0]+y_test.value_counts()[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoGTfy-shKhY"
      },
      "outputs": [],
      "source": [
        "# Revisión de la proporción de nulos por variable\n",
        "X_train.isnull().mean().where(X_train.isnull().mean()>0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99aXZoodKQp-"
      },
      "source": [
        "### Variable numéricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdQFzpchotjo"
      },
      "outputs": [],
      "source": [
        "var_num = X_train.select_dtypes(include = [\"number\"])\n",
        "var_num.isnull().mean().where(var_num.isnull().mean()>0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVwSOBDAKbym"
      },
      "source": [
        "### Variables categóricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tG0divc104W"
      },
      "outputs": [],
      "source": [
        "var_cat = X_train.select_dtypes(exclude = [\"number\"])\n",
        "var_cat.isnull().mean().where(var_cat.isnull().mean()>0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generamos un pipeline para tratamiento de Nulos"
      ],
      "metadata": {
        "id": "WXP8fC059q_c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGO1U4bne9mO"
      },
      "outputs": [],
      "source": [
        "# Llamemos a la librería feature engine\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "from feature_engine.imputation import ArbitraryNumberImputer\n",
        "from feature_engine.imputation import CategoricalImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_lSZmOv7D96"
      },
      "outputs": [],
      "source": [
        "# Construyamos alternativamente un nuevo pipeline con todos los métodos de imputación en uno solo\n",
        "pipe_2 = Pipeline(\n",
        "    [\n",
        "        (\n",
        "            \"median_imputer\",\n",
        "            MeanMedianImputer(imputation_method=\"median\", variables=['LINEA_DE_TC','EDAD_T','INGRESO_CLIENTE']),\n",
        "        ),\n",
        "        (\n",
        "            \"arbitrary_imputer\",\n",
        "            ArbitraryNumberImputer(arbitrary_number=0, variables=['CUOTA', 'DEUDA_TOTAL_SISTEMA', 'MEDIANA_AHORROS_ULT_6M', 'MESES_AHORROS_ULT_6M', 'ATRASO_MAXIMO_ULT_24M','ATRASO_MAXIMO_ULT_12M','MONTO_TC_MEMBRESIA']),\n",
        "        ),\n",
        "        (   \"mode_imputer\",\n",
        "           CategoricalImputer(imputation_method=\"frequent\", variables=['PROFESION','ZONA_DEL_DESEMBOLSO','ESTADO_CIVIL'])\n",
        "        ),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjsnBIt_98-4"
      },
      "outputs": [],
      "source": [
        "pipe_2.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_2.named_steps[\"median_imputer\"].imputer_dict_"
      ],
      "metadata": {
        "id": "NXRem7oEyAE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_2.named_steps[\"arbitrary_imputer\"].imputer_dict_"
      ],
      "metadata": {
        "id": "J6XTHXJpyDLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_2.named_steps['mode_imputer'].imputer_dict_"
      ],
      "metadata": {
        "id": "94wjct8ZyGxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GwyjwW4987v"
      },
      "outputs": [],
      "source": [
        "X_train_t = pipe_2.transform(X_train)\n",
        "X_test_t = pipe_2.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWKj84BG_RR8"
      },
      "outputs": [],
      "source": [
        "X_train_t.isnull().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_8gISoe_V-j"
      },
      "outputs": [],
      "source": [
        "X_test_t.isnull().mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ba14EMaIGKI"
      },
      "source": [
        "### 3.2 Tratamiento de Valores Raros o Poco frecuentes\n",
        "En este punto, nos detenemos para revisar problemas de cardinalidad y si existen valores raros o poco frecuentes en nuestras variables categóricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hi8S1nlPKDy"
      },
      "outputs": [],
      "source": [
        "cat_cols=['FLG_GARANTIA','SEGMENTOCLIENTE','TARJETA_RELACIONADA','VEHICULAR_RELACIONADA','HIPOTECARIO_RELACIONADA','CLASIF_SISTEMA_ULT_12M',\n",
        "          'FLG_PDH','PROFESION','ZONA_DEL_DESEMBOLSO','ESTADO_CIVIL','FLG_TC_VISA','FLG_TC_MC']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAWGz0gxNAIq"
      },
      "outputs": [],
      "source": [
        "# Examinemos esto en la muestra de train\n",
        "for col in cat_cols:\n",
        "    print('variable: ', col, ' nro de categorias: ', X_train_t[col].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWqsEfKWM_y9"
      },
      "outputs": [],
      "source": [
        "#Examinemos esto en la muestra de test\n",
        "for col in cat_cols:\n",
        "    print('variable: ', col, ' nro de categorias: ', X_test_t[col].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTShRUdPQ4yv"
      },
      "outputs": [],
      "source": [
        "# Analicemos la variable Profesión\n",
        "unique_to_train_set = [x for x in X_train_t.PROFESION.unique() if x not in X_test_t.PROFESION.unique()]\n",
        "print('El nro de categorias que aparecen en el train y no en el test es', len(unique_to_train_set))\n",
        "unique_to_test_set = [x for x in X_test_t.PROFESION.unique() if x not in X_train_t.PROFESION.unique()]\n",
        "print('El nro de categorias que aparecen en el test y no en el train es', len(unique_to_test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHglBNCzQRew"
      },
      "outputs": [],
      "source": [
        "# Analicemos la variable SEGMENTOCLIENTE\n",
        "unique_to_train_set = [x for x in X_train_t.SEGMENTOCLIENTE.unique() if x not in X_test_t.SEGMENTOCLIENTE.unique()]\n",
        "print('El nro de categorias que aparecen en el train y no en el test es', len(unique_to_train_set))\n",
        "unique_to_test_set = [x for x in X_test_t.SEGMENTOCLIENTE.unique() if x not in X_train_t.SEGMENTOCLIENTE.unique()]\n",
        "print('El nro de categorias que aparecen en el test y no en el train es', len(unique_to_test_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOjKU4nRSsm7"
      },
      "source": [
        "#### Generamos un pipeline para tratamiento de valores raros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OI0-nbuO6z4J"
      },
      "outputs": [],
      "source": [
        "from feature_engine.encoding import RareLabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6WPmL2Aaufy"
      },
      "outputs": [],
      "source": [
        "# Construyamos alternativamente un nuevo pipeline con todos los métodos de imputación y codificación de valores raros en uno solo\n",
        "pipe_3 = Pipeline(\n",
        "    [\n",
        "        (\n",
        "            \"median_imputer\",\n",
        "            MeanMedianImputer(imputation_method=\"median\", variables=['LINEA_DE_TC','EDAD_T','INGRESO_CLIENTE']),\n",
        "        ),\n",
        "        (\n",
        "            \"arbitrary_imputer\",\n",
        "            ArbitraryNumberImputer(arbitrary_number=0, variables=['CUOTA', 'DEUDA_TOTAL_SISTEMA', 'MEDIANA_AHORROS_ULT_6M', 'MESES_AHORROS_ULT_6M', 'ATRASO_MAXIMO_ULT_24M','ATRASO_MAXIMO_ULT_12M','MONTO_TC_MEMBRESIA']),\n",
        "        ),\n",
        "        (   \"mode_imputer\",\n",
        "           CategoricalImputer(imputation_method=\"frequent\", variables=['PROFESION','ZONA_DEL_DESEMBOLSO','ESTADO_CIVIL'])\n",
        "        ),\n",
        "        (\n",
        "            \"rare_encoder\",\n",
        "            RareLabelEncoder(tol=0.01,n_categories=5,variables=[\"PROFESION\",\"SEGMENTOCLIENTE\",])\n",
        "        ),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpWg6o9jauav"
      },
      "outputs": [],
      "source": [
        "pipe_3.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TB1MU-GzauLm"
      },
      "outputs": [],
      "source": [
        "X_train_t = pipe_3.transform(X_train)\n",
        "X_test_t = pipe_3.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobando el funcionamiento del pipeline\n",
        "# Analicemos la variable PROFESION\n",
        "unique_to_train_set = [x for x in X_train_t.PROFESION.unique() if x not in X_test_t.PROFESION.unique()]\n",
        "print('El nro de categorias que aparecen en el train y no en el test es', len(unique_to_train_set))\n",
        "unique_to_test_set = [x for x in X_test_t.PROFESION.unique() if x not in X_train_t.PROFESION.unique()]\n",
        "print('El nro de categorias que aparecen en el test y no en el train es', len(unique_to_test_set))"
      ],
      "metadata": {
        "id": "U8dQ4q2s0B9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6W_64TyvcJgg"
      },
      "outputs": [],
      "source": [
        "# Analicemos la variable SEGMENTOCLIENTE\n",
        "unique_to_train_set = [x for x in X_train_t.SEGMENTOCLIENTE.unique() if x not in X_test_t.SEGMENTOCLIENTE.unique()]\n",
        "print('El nro de categorias que aparecen en el train y no en el test es', len(unique_to_train_set))\n",
        "unique_to_test_set = [x for x in X_test_t.SEGMENTOCLIENTE.unique() if x not in X_train_t.SEGMENTOCLIENTE.unique()]\n",
        "print('El nro de categorias que aparecen en el test y no en el train es', len(unique_to_test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCU5CWHCXnKv"
      },
      "outputs": [],
      "source": [
        "X_train_t.PROFESION.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24tjkOMzVngq"
      },
      "outputs": [],
      "source": [
        "X_train_t.SEGMENTOCLIENTE.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PDwaO9kcQzY"
      },
      "source": [
        "### IMPORTANTE: Hasta aqui tenemos un pipeline para imputar nuestras variables numéricas y categóricas en caso de missing, además de generar un grupo de casos \"Raros\" para las variables categóricas donde encontramos problemas."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Tratamiento de Outliers y Escalamiento"
      ],
      "metadata": {
        "id": "D_MMrD_u4pHu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tOoN2hc59Ry"
      },
      "outputs": [],
      "source": [
        "X_train_t.describe().transpose()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outliers_col(X_train_t)"
      ],
      "metadata": {
        "id": "AqkKkkBI-h-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols=['DEUDA', 'ATRASO_MAXIMO_ULT_6M','ATRASO_MAXIMO_ULT_12M', 'ATRASO_MAXIMO_ULT_24M',\n",
        "          'MEDIANA_AHORROS_ULT_6M', 'DEUDA_TOTAL_SISTEMA', 'MONTO_TC_SISTEMA', 'INGRESO_CLIENTE','EDAD_T','CUOTA',\n",
        "          'LINEA_DE_TC', 'MONTO_TC_MEMBRESIA']"
      ],
      "metadata": {
        "id": "8Yqwkkyj7F-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQq1lhg259Rz"
      },
      "outputs": [],
      "source": [
        "from feature_engine.outliers import Winsorizer\n",
        "capper = Winsorizer(\n",
        "    variables=num_cols,\n",
        "    capping_method=\"quantiles\",\n",
        "    tail=\"right\",\n",
        "    fold=0.01,\n",
        ")\n",
        "capper.fit(X_train_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-jycqVd59Rz"
      },
      "outputs": [],
      "source": [
        "#capper.right_tail_caps_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKGIbnNo59Rz"
      },
      "outputs": [],
      "source": [
        "X_train_t = capper.transform(X_train_t)\n",
        "X_test_t = capper.transform(X_test_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__zGPGaS59R0"
      },
      "outputs": [],
      "source": [
        "#plot_boxplot_and_hist(X_train_t2, \"var\")\n",
        "X_train_t.describe().transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8JiXFoc59R0"
      },
      "source": [
        "### Ahora hagamos el escalado de variables de las variables numéricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZ6rFyNs59R0"
      },
      "outputs": [],
      "source": [
        "#from sklearn.preprocessing import MinMaxScaler\n",
        "#scaler = MinMaxScaler().set_output(transform=\"pandas\")\n",
        "#scaler.fit(X_train)\n",
        "#X_train_scaled = scaler.transform(X_train)\n",
        "#X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols=['DEUDA', 'PLAZO_CREDITO', 'ATRASO_MAXIMO_ULT_6M','ATRASO_MAXIMO_ULT_12M', 'ATRASO_MAXIMO_ULT_24M','MESES_AHORROS_ULT_6M',\n",
        "          'MEDIANA_AHORROS_ULT_6M', 'DEUDA_TOTAL_SISTEMA','NUMERO_DE_PAGOS_PDH', 'MONTO_TC_SISTEMA', 'INGRESO_CLIENTE', 'EDAD_T','CUOTA',\n",
        "          'LINEA_DE_TC', 'MONTO_TC_MEMBRESIA']"
      ],
      "metadata": {
        "id": "GMaM0j8DC2kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTgM71VI59R0"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = RobustScaler().set_output(transform=\"pandas\")\n",
        "scaler.fit(X_train_t[num_cols])\n",
        "X_train_t_numoutscal = scaler.transform(X_train_t[num_cols])\n",
        "X_test_t_numoutscal = scaler.transform(X_test_t[num_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1u-Si8d59R0"
      },
      "outputs": [],
      "source": [
        "X_train_t_numoutscal.describe().transpose()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer"
      ],
      "metadata": {
        "id": "dtqIAzPc59R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actualicemos nuestro pipeline\n",
        "pipe_4 = Pipeline(\n",
        "    [\n",
        "        (\n",
        "            \"median_imputer\",\n",
        "            MeanMedianImputer(imputation_method=\"median\", variables=['LINEA_DE_TC','EDAD_T','INGRESO_CLIENTE'])\n",
        "        ),\n",
        "        (\n",
        "            \"arbitrary_imputer\",\n",
        "            ArbitraryNumberImputer(arbitrary_number=0, variables=['CUOTA', 'DEUDA_TOTAL_SISTEMA', 'MEDIANA_AHORROS_ULT_6M', 'MESES_AHORROS_ULT_6M', 'ATRASO_MAXIMO_ULT_24M','ATRASO_MAXIMO_ULT_12M','MONTO_TC_MEMBRESIA']),\n",
        "        ),\n",
        "        (   \"mode_imputer\",\n",
        "           CategoricalImputer(imputation_method=\"frequent\", variables=['PROFESION','ZONA_DEL_DESEMBOLSO','ESTADO_CIVIL'])\n",
        "        ),\n",
        "        (\n",
        "            \"rare_encoder\",\n",
        "            RareLabelEncoder(tol=0.01,n_categories=5,variables=[\"PROFESION\",\"SEGMENTOCLIENTE\",])\n",
        "        ),\n",
        "        (   \"capper\",\n",
        "            Winsorizer(variables=['DEUDA', 'ATRASO_MAXIMO_ULT_6M','ATRASO_MAXIMO_ULT_12M', 'ATRASO_MAXIMO_ULT_24M',\n",
        "          'MEDIANA_AHORROS_ULT_6M', 'DEUDA_TOTAL_SISTEMA', 'MONTO_TC_SISTEMA', 'INGRESO_CLIENTE','EDAD_T','CUOTA',\n",
        "          'LINEA_DE_TC', 'MONTO_TC_MEMBRESIA'], capping_method=\"quantiles\", tail=\"right\", fold=0.01)\n",
        "        ),\n",
        "        (   \"scaler\",\n",
        "            ColumnTransformer(transformers=[('e', RobustScaler(), ['DEUDA', 'PLAZO_CREDITO', 'ATRASO_MAXIMO_ULT_6M','ATRASO_MAXIMO_ULT_12M', 'ATRASO_MAXIMO_ULT_24M','MESES_AHORROS_ULT_6M',\n",
        "          'MEDIANA_AHORROS_ULT_6M', 'DEUDA_TOTAL_SISTEMA','NUMERO_DE_PAGOS_PDH', 'MONTO_TC_SISTEMA', 'INGRESO_CLIENTE', 'EDAD_T','CUOTA',\n",
        "          'LINEA_DE_TC', 'MONTO_TC_MEMBRESIA'])],remainder='passthrough',verbose_feature_names_out=False).set_output(transform=\"pandas\")\n",
        "\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "h6BMkmNq59R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_4.fit(X_train)"
      ],
      "metadata": {
        "id": "jcy3BiSm59R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_t = pipe_4.transform(X_train)\n",
        "X_test_t = pipe_4.transform(X_test)"
      ],
      "metadata": {
        "id": "tWd9EBm-59R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_t.describe().transpose()"
      ],
      "metadata": {
        "id": "HY90brMu4odY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljtYIk9VGDks"
      },
      "source": [
        "## **4. Feature Selection**\n",
        "Ahora, podemos determinar cuanto aportan estas variables? para esto calculemos su IV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hbk61CO_HY4B"
      },
      "outputs": [],
      "source": [
        "tot_train_t=pd.concat([X_train_t[cat_cols], y_train], axis=1)\n",
        "tot_train_t.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axrO1Wt3GC4K"
      },
      "outputs": [],
      "source": [
        "def calculate_woe_iv(dataset, feature_cat, target):\n",
        "    lst = []\n",
        "    feature=feature_cat\n",
        "    for i in range(dataset[feature].nunique()):\n",
        "        val = list(dataset[feature].unique())[i]\n",
        "        lst.append({\n",
        "            'Value': val,\n",
        "            'All': dataset[dataset[feature] == val].count()[feature],\n",
        "            'Good': dataset[(dataset[feature] == val) & (dataset[target] == 0)].count()[feature],\n",
        "            'Bad': dataset[(dataset[feature] == val) & (dataset[target] == 1)].count()[feature]\n",
        "        })\n",
        "    dset = pd.DataFrame(lst)\n",
        "    dset['Distr_Good'] = dset['Good'] / dset['Good'].sum()\n",
        "    dset['Distr_Bad'] = dset['Bad'] / dset['Bad'].sum()\n",
        "    dset['WoE'] = np.log(dset['Distr_Good'] / dset['Distr_Bad'])\n",
        "    dset = dset.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n",
        "    dset['IV'] = (dset['Distr_Good'] - dset['Distr_Bad']) * dset['WoE']\n",
        "    iv = dset['IV'].sum()\n",
        "    dset = dset.sort_values(by='WoE')\n",
        "    return iv, dset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qx6JwfhiRp5s"
      },
      "outputs": [],
      "source": [
        "def plot_by_woe(df_WoE, rotation_of_x_axis_labels = 0):\n",
        "    x = np.array(df_WoE.iloc[:, 0].apply(str))\n",
        "    y = df_WoE['WoE']\n",
        "    plt.figure(figsize=(18, 6))\n",
        "    plt.plot(x, y, marker = 'o', linestyle = '--', color = 'k')\n",
        "    plt.xlabel(df_WoE.columns[0])\n",
        "    plt.ylabel('WOE')\n",
        "    plt.title(str('WOE por ' + df_WoE.columns[0]))\n",
        "    plt.xticks(rotation = rotation_of_x_axis_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIRnJYumZ91Q"
      },
      "source": [
        "### Generemos un reporte con todas los IVs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EK9JgS_Y8gs"
      },
      "outputs": [],
      "source": [
        "def getFeatureIV_Importance(df,features,target):\n",
        "    featureIV_Importance=list()\n",
        "    for v in features:\n",
        "      iv, rep=calculate_woe_iv(df,v,target)\n",
        "      featureIV_Importance.append(iv)\n",
        "    display(pd.DataFrame({\"Feature\":features, \"IV\":featureIV_Importance}).sort_values(\"IV\",ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Variables Categóricas"
      ],
      "metadata": {
        "id": "Old8w51TDxIS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8LskV-5bp6e"
      },
      "outputs": [],
      "source": [
        "getFeatureIV_Importance(tot_train_t,cat_cols,\"FLG_DEFAULT_12M\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6IJKTQQdcgp"
      },
      "source": [
        "### En este punto, quedémonos solo con las variables cuyo IV es mayor al 2% y menor a 50%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zC1QlXI_dbl1"
      },
      "outputs": [],
      "source": [
        "cat_cols_2=['SEGMENTOCLIENTE','CLASIF_SISTEMA_ULT_12M','FLG_PDH','PROFESION','ZONA_DEL_DESEMBOLSO','ESTADO_CIVIL','FLG_GARANTIA','HIPOTECARIO_RELACIONADA']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pYkFqcLrlSk"
      },
      "source": [
        "### Codificación de variables categóricas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knZ2W99r_fU3"
      },
      "outputs": [],
      "source": [
        "from feature_engine.encoding import WoEEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJM_1hEDGtX_"
      },
      "outputs": [],
      "source": [
        "encoder_2 = WoEEncoder(variables=['SEGMENTOCLIENTE','CLASIF_SISTEMA_ULT_12M','FLG_PDH','PROFESION','ZONA_DEL_DESEMBOLSO','ESTADO_CIVIL',\n",
        "                                  'FLG_GARANTIA','HIPOTECARIO_RELACIONADA'],\n",
        "                       fill_value=0) #ignore_format=False\n",
        "encoder_2.fit(X_train_t[cat_cols_2], y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEaN3hIZGtUW"
      },
      "outputs": [],
      "source": [
        "# encoder_2.encoder_dict_\n",
        "# encoder_2.variables_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzCO1Sj-OcmU"
      },
      "outputs": [],
      "source": [
        "X_train_woe_enc = encoder_2.transform(X_train_t[cat_cols_2])\n",
        "X_test_woe_enc = encoder_2.transform(X_test_t[cat_cols_2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_2KTs5HOceR"
      },
      "outputs": [],
      "source": [
        "X_train_woe_enc.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTh6ioBKNOxn"
      },
      "source": [
        "### 4.2 Variables numéricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w35SeP4iNiKH"
      },
      "outputs": [],
      "source": [
        "X_train_t.select_dtypes(include=['number']).columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8wG7L2YOpcQ"
      },
      "outputs": [],
      "source": [
        "num_cols=['DEUDA', 'PLAZO_CREDITO', 'ATRASO_MAXIMO_ULT_6M','ATRASO_MAXIMO_ULT_12M', 'ATRASO_MAXIMO_ULT_24M','MESES_AHORROS_ULT_6M',\n",
        "          'MEDIANA_AHORROS_ULT_6M', 'DEUDA_TOTAL_SISTEMA','NUMERO_DE_PAGOS_PDH', 'MONTO_TC_SISTEMA', 'INGRESO_CLIENTE', 'EDAD_T','CUOTA',\n",
        "          'LINEA_DE_TC', 'MONTO_TC_MEMBRESIA']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### En este punto discretizo para luego encontrar el IV de las variables"
      ],
      "metadata": {
        "id": "8psoLfeKHJbI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFci4lftPSGC"
      },
      "outputs": [],
      "source": [
        "from feature_engine.discretisation import EqualFrequencyDiscretiser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBXnCKSdHwHk"
      },
      "outputs": [],
      "source": [
        "disc1 = EqualFrequencyDiscretiser(q=10,\n",
        "                                  variables=num_cols,\n",
        "                                  return_boundaries=True,)\n",
        "disc1.fit(X_train_t[num_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHWvBIYgNA_D"
      },
      "outputs": [],
      "source": [
        "#disc1.binner_dict_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a85vYL_HwDZ"
      },
      "outputs": [],
      "source": [
        "X_train_t_numdisc=disc1.transform(X_train_t[num_cols])\n",
        "X_test_t_numdisc=disc1.transform(X_test_t[num_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hqpt_LTHHv-w"
      },
      "outputs": [],
      "source": [
        "X_train_t_numdisc.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV-SooDrhAcX"
      },
      "source": [
        "### Veamos cuales son las variables numéricas más importantes, basado en su IV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tot_train_t2=pd.concat([X_train_t_numdisc, y_train], axis=1)\n",
        "tot_train_t2.head()"
      ],
      "metadata": {
        "id": "DXgSZiPnL3jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMvQHBNNcUkB"
      },
      "outputs": [],
      "source": [
        "getFeatureIV_Importance(tot_train_t2,num_cols,\"FLG_DEFAULT_12M\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iwE3WRyjxh9"
      },
      "source": [
        "### Nuevamente, en este punto también solo quedémonos con las variables numéricas con IV mayor a 2% y menor a 50%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs3t5gM8cUb8"
      },
      "outputs": [],
      "source": [
        "num_cols_2=['MEDIANA_AHORROS_ULT_6M','INGRESO_CLIENTE','MESES_AHORROS_ULT_6M','NUMERO_DE_PAGOS_PDH','PLAZO_CREDITO','LINEA_DE_TC','EDAD_T',\n",
        "            'MONTO_TC_MEMBRESIA','DEUDA','ATRASO_MAXIMO_ULT_24M','DEUDA_TOTAL_SISTEMA','ATRASO_MAXIMO_ULT_12M']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buleY20fnNzm"
      },
      "source": [
        "### Actualizamos nuestro pipeline con todo el flujo de tratamiento de datos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_5 = Pipeline(\n",
        "    [\n",
        "        (   \"median_imputer\",\n",
        "            MeanMedianImputer(imputation_method=\"median\", variables=['LINEA_DE_TC','EDAD_T','INGRESO_CLIENTE'])\n",
        "        ),\n",
        "        (   \"arbitrary_imputer\",\n",
        "            ArbitraryNumberImputer(arbitrary_number=0, variables=['CUOTA', 'DEUDA_TOTAL_SISTEMA', 'MEDIANA_AHORROS_ULT_6M', 'MESES_AHORROS_ULT_6M', 'ATRASO_MAXIMO_ULT_24M','ATRASO_MAXIMO_ULT_12M','MONTO_TC_MEMBRESIA']),\n",
        "        ),\n",
        "        (   \"mode_imputer\",\n",
        "           CategoricalImputer(imputation_method=\"frequent\", variables=['PROFESION','ZONA_DEL_DESEMBOLSO','ESTADO_CIVIL'])\n",
        "        ),\n",
        "        (   \"rare_encoder\",\n",
        "            RareLabelEncoder(tol=0.01,n_categories=5,variables=[\"PROFESION\",\"SEGMENTOCLIENTE\",])\n",
        "        ),\n",
        "        (   \"capper\",\n",
        "            Winsorizer(variables=['DEUDA', 'ATRASO_MAXIMO_ULT_6M','ATRASO_MAXIMO_ULT_12M', 'ATRASO_MAXIMO_ULT_24M',\n",
        "          'MEDIANA_AHORROS_ULT_6M', 'DEUDA_TOTAL_SISTEMA', 'MONTO_TC_SISTEMA', 'INGRESO_CLIENTE','EDAD_T','CUOTA',\n",
        "          'LINEA_DE_TC', 'MONTO_TC_MEMBRESIA'], capping_method=\"quantiles\", tail=\"right\", fold=0.01)\n",
        "        ),\n",
        "        (   \"scaler\",\n",
        "            ColumnTransformer(transformers=[('e', RobustScaler(), ['DEUDA', 'PLAZO_CREDITO', 'ATRASO_MAXIMO_ULT_6M','ATRASO_MAXIMO_ULT_12M', 'ATRASO_MAXIMO_ULT_24M','MESES_AHORROS_ULT_6M',\n",
        "          'MEDIANA_AHORROS_ULT_6M', 'DEUDA_TOTAL_SISTEMA','NUMERO_DE_PAGOS_PDH', 'MONTO_TC_SISTEMA', 'INGRESO_CLIENTE', 'EDAD_T','CUOTA',\n",
        "          'LINEA_DE_TC', 'MONTO_TC_MEMBRESIA'])],remainder='passthrough',verbose_feature_names_out=False).set_output(transform=\"pandas\")\n",
        "        ),\n",
        "        (   \"encoder_2\",\n",
        "            WoEEncoder(variables=['SEGMENTOCLIENTE','CLASIF_SISTEMA_ULT_12M','FLG_PDH','PROFESION','ZONA_DEL_DESEMBOLSO','ESTADO_CIVIL',\n",
        "                                  'FLG_GARANTIA','HIPOTECARIO_RELACIONADA'],\n",
        "                       fill_value=0)\n",
        "        ),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "JWiSx_y5IVtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_5.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "fRm0VWAJo2Os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_t_p = pipe_5.transform(X_train)\n",
        "X_test_t_p = pipe_5.transform(X_test)"
      ],
      "metadata": {
        "id": "w7c2WUG7o2MG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y14B14kp8yR8"
      },
      "source": [
        "### 4.3 Análisis de Correlaciones\n",
        "En este punto, verifiquemos si existe correlación en las variables predictoras que hemos elegido, con el fin de depurarlas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMh5mKAs_5ow"
      },
      "outputs": [],
      "source": [
        "# Creemos una función para identificar de manera masiva a las variables correlacionadas, en caso de tener un mayor volumen de variables\n",
        "def correlation(dataset, threshold):\n",
        "    col_corr = set()\n",
        "    corr_matrix = dataset.corr()\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
        "                print(abs(corr_matrix.iloc[i, j]), corr_matrix.columns[i], corr_matrix.columns[j])\n",
        "                colname = corr_matrix.columns[j]\n",
        "                col_corr.add(colname)\n",
        "    return col_corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w704NZvLD4Ar"
      },
      "outputs": [],
      "source": [
        "X_train_t2=pd.concat([X_train_t_p[cat_cols_2], X_train_t_p[num_cols_2]], axis=1)\n",
        "X_test_t2=pd.concat([X_test_t_p[cat_cols_2], X_test_t_p[num_cols_2]], axis=1)\n",
        "X_train_t2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JD_rOp2tD31X"
      },
      "outputs": [],
      "source": [
        "corr_features = correlation(X_train_t2, 0.8)\n",
        "len(set(corr_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBGrWHOK9BGa"
      },
      "outputs": [],
      "source": [
        "# Si hubiesen variables correlacionadas deberían ser extraidas, de la siguiente forma\n",
        "# X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
        "# X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
        "# X_train.shape, X_test.shape\n",
        "# Alternativamente, podemos hacer lo siguiente\n",
        "#from feature_engine.selection import DropCorrelatedFeatures\n",
        "#sel = DropCorrelatedFeatures(\n",
        "#    threshold=0.8,\n",
        "#    method='pearson',\n",
        "#    missing_values='ignore'\n",
        "#)\n",
        "#sel.fit(X_train)\n",
        "#X_train = sel.transform(X_train)\n",
        "#X_test = sel.transform(X_test)\n",
        "#X_train.shape, X_test.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMNjQHF5hrwg"
      },
      "source": [
        "### Alternativamente usaremos las variables numéricas discretizadas y codificadas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_t_numdisc.shape"
      ],
      "metadata": {
        "id": "YPU0R6qOLLYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYAQaTX6io5O"
      },
      "outputs": [],
      "source": [
        "encoder_4 = WoEEncoder(variables=num_cols_2,\n",
        "                       fill_value=0) #ignore_format=False\n",
        "encoder_4.fit(X_train_t_numdisc[num_cols_2], y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiDQHMEVio2I"
      },
      "outputs": [],
      "source": [
        "X_train_woe_enc2 = encoder_4.transform(X_train_t_numdisc[num_cols_2])\n",
        "X_test_woe_enc2 = encoder_4.transform(X_test_t_numdisc[num_cols_2])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_woe_enc2.head()"
      ],
      "metadata": {
        "id": "gOnNKYa7QfRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dyk77sp7mCM-"
      },
      "source": [
        "## **5. Entrenamiento del Modelo**\n",
        "En esta sección construiremos tres tipos de modelos y los evaluaremos para quedarnos con el mejor de ellos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "Hmu_8mpNEhyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logit = LogisticRegression()\n",
        "logit.fit(X_train_t2, y_train)\n",
        "pred_train_logit = logit.predict_proba(X_train_t2)\n",
        "pred_test_logit = logit.predict_proba(X_test_t2)\n",
        "print('Train set')\n",
        "print('Logistic regression roc-auc: {}'.format(roc_auc_score(y_train, pred_train_logit[:,1])))\n",
        "print('Test set')\n",
        "print('Logistic regression roc-auc: {}'.format(roc_auc_score(y_test, pred_test_logit[:,1])))"
      ],
      "metadata": {
        "id": "jz5ILFJCVsrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=300, random_state=39)\n",
        "rf.fit(X_train_t2, y_train)\n",
        "pred_train_rf = rf.predict_proba(X_train_t2)\n",
        "pred_test_rf = rf.predict_proba(X_test_t2)\n",
        "print('Train set')\n",
        "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred_train_rf[:,1])))\n",
        "print('Test set')\n",
        "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred_test_rf[:,1])))"
      ],
      "metadata": {
        "id": "FvvKACyjEgDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbc = GradientBoostingClassifier(n_estimators=300, random_state=44)\n",
        "gbc.fit(X_train_t2, y_train)\n",
        "pred_train_gbc = gbc.predict_proba(X_train_t2)\n",
        "pred_test_gbc = gbc.predict_proba(X_test_t2)\n",
        "print('Train set')\n",
        "print('Gradient Boosted Trees roc-auc: {}'.format(roc_auc_score(y_train, pred_train_gbc[:,1])))\n",
        "print('Test set')\n",
        "print('Gradient Boosted Trees roc-auc: {}'.format(roc_auc_score(y_test, pred_test_gbc[:,1])))"
      ],
      "metadata": {
        "id": "VeUEKzUbFZg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### IMPORTANTE: Hasta aqui tenemos un modelo ganador por estabilidad entre train y test< entonces revisemos como podemos optimizar sus hiperparámetros para reducir este efecto"
      ],
      "metadata": {
        "id": "o6byc4v2ZczY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV"
      ],
      "metadata": {
        "id": "m0KuuNvqZb7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Random Forest**"
      ],
      "metadata": {
        "id": "kmEtkf7IomdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluemos que la sensibilidad de cada hiperparámetro"
      ],
      "metadata": {
        "id": "BBmf6IG8d4EX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nro de árboles\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0ZFRasn4eJCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random forests\n",
        "rf = RandomForestClassifier(random_state=39)\n",
        "\n",
        "# hyperparameter space\n",
        "rf_param_grid = dict(\n",
        "    n_estimators=[10, 20, 50, 100, 200],\n",
        "#     max_depth=[1, 2, 3, 4, 5],\n",
        "#     min_samples_split=[0.01, 0.05, 0.1, 0.2, 0.3, 0.5]\n",
        ")\n",
        "\n",
        "# search\n",
        "reg = GridSearchCV(rf, rf_param_grid,scoring='roc_auc', return_train_score=True, cv=5, n_jobs=4)\n",
        "search = reg.fit(pd.concat([X_train_woe_enc,X_train_t_numoutscal],axis=1), y_train)\n",
        "\n",
        "# best hyperparameters\n",
        "search.best_params_"
      ],
      "metadata": {
        "id": "4sQWrMfocwID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(search.cv_results_)[['params','mean_train_score', 'std_train_score', 'mean_test_score', 'std_test_score']]\n",
        "results"
      ],
      "metadata": {
        "id": "DV2L3aEXjiO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot results\n",
        "results.index = rf_param_grid['n_estimators']\n",
        "results['mean_train_score'].plot(yerr=[results['std_train_score'], results['std_train_score']], subplots=True)\n",
        "results['mean_test_score'].plot(yerr=[results['std_test_score'], results['std_test_score']], subplots=True)\n",
        "plt.ylim(0.6, 1)\n",
        "plt.ylabel('roc_auc')\n",
        "plt.xlabel('n_estimators')"
      ],
      "metadata": {
        "id": "5apY-4X8cwEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Profundidad"
      ],
      "metadata": {
        "id": "Wp1l3dkseNMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random forests\n",
        "rf = RandomForestClassifier(random_state=39)\n",
        "\n",
        "# hyperparameter space\n",
        "rf_param_grid = dict(\n",
        "#     n_estimators=[10, 20, 50, 100, 200],\n",
        "      max_depth=[1, 2, 3, 4, 5],\n",
        "#     min_samples_split=[0.01, 0.05, 0.1, 0.2, 0.3, 0.5]\n",
        ")\n",
        "\n",
        "# search\n",
        "reg = GridSearchCV(rf, rf_param_grid,scoring='roc_auc', return_train_score=True, cv=5, n_jobs=4)\n",
        "search = reg.fit(pd.concat([X_train_woe_enc,X_train_t_numoutscal],axis=1), y_train)\n",
        "\n",
        "# best hyperparameters\n",
        "search.best_params_"
      ],
      "metadata": {
        "id": "my3rnD4McwBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(search.cv_results_)[['params', 'mean_train_score', 'std_train_score', 'mean_test_score', 'std_test_score']]\n",
        "results"
      ],
      "metadata": {
        "id": "1HDlV29ocv-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot results\n",
        "results.index = rf_param_grid['max_depth']\n",
        "results['mean_train_score'].plot(yerr=[results['std_train_score'], results['std_train_score']], subplots=True)\n",
        "results['mean_test_score'].plot(yerr=[results['std_test_score'], results['std_test_score']], subplots=True)\n",
        "plt.ylim(0.6, 1)\n",
        "plt.ylabel('roc_auc')\n",
        "plt.xlabel('max_depth')"
      ],
      "metadata": {
        "id": "WpUn7xNNj_8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nro mínimo de observaciones para partir el nodo"
      ],
      "metadata": {
        "id": "YKsb8i2FeSP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random forests\n",
        "rf = RandomForestClassifier(random_state=39)\n",
        "\n",
        "# hyperparameter space\n",
        "rf_param_grid = dict(\n",
        "#     n_estimators=[10, 20, 50, 100, 200],\n",
        "#     max_depth=[1, 2, 3, 4, 5],\n",
        "      min_samples_split=[0.01, 0.05, 0.1, 0.2, 0.3, 0.5]\n",
        ")\n",
        "\n",
        "# search\n",
        "reg = GridSearchCV(rf, rf_param_grid,scoring='roc_auc', return_train_score=True, cv=5, n_jobs=4)\n",
        "search = reg.fit(pd.concat([X_train_woe_enc,X_train_t_numoutscal],axis=1), y_train)\n",
        "\n",
        "# best hyperparameters\n",
        "search.best_params_"
      ],
      "metadata": {
        "id": "T-QT2wFGh5oQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(search.cv_results_)[['params', 'mean_train_score', 'std_train_score', 'mean_test_score', 'std_test_score']]\n",
        "results"
      ],
      "metadata": {
        "id": "4DCz6wjsFZZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot results\n",
        "results.index = rf_param_grid['min_samples_split']\n",
        "results['mean_train_score'].plot(yerr=[results['std_train_score'], results['std_train_score']], subplots=True)\n",
        "results['mean_test_score'].plot(yerr=[results['std_test_score'], results['std_test_score']], subplots=True)\n",
        "plt.ylim(0.6, 1)\n",
        "plt.ylabel('roc_auc')\n",
        "plt.xlabel('min_samples_split')"
      ],
      "metadata": {
        "id": "FmRRsKy2kRXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Veamos el GridSearch con todos los parámetros para evaluar la mejor combinación"
      ],
      "metadata": {
        "id": "TpsEPtIGp2zP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random forests\n",
        "rf = RandomForestClassifier(random_state=39)\n",
        "\n",
        "# hyperparameter space\n",
        "rf_param_grid = dict(\n",
        "    n_estimators=[10, 20, 50, 100, 200],# 5 valores\n",
        "    max_depth=[1, 2, 3, 4, 5],#5 valores\n",
        "    min_samples_split=[0.01, 0.05, 0.1, 0.2, 0.3, 0.5] #6 valores\n",
        ")\n",
        "\n",
        "# search\n",
        "reg = GridSearchCV(rf, rf_param_grid,scoring='roc_auc',return_train_score=True, cv=5, n_jobs=4)\n",
        "search = reg.fit(pd.concat([X_train_woe_enc,X_train_t_numoutscal],axis=1), y_train)\n",
        "\n",
        "# best hyperparameters\n",
        "search.best_params_"
      ],
      "metadata": {
        "id": "wrHX3sjzkRTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(search.cv_results_)[['params', 'mean_train_score', 'std_train_score','mean_test_score', 'std_test_score']]\n",
        "results.sort_values(by='mean_test_score', ascending=False, inplace=True)\n",
        "results.reset_index(drop=True, inplace=True)\n",
        "results"
      ],
      "metadata": {
        "id": "Mdh-A7L8kRNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['mean_train_score'].plot(yerr=[results['std_train_score'], results['std_train_score']], subplots=True)\n",
        "results['mean_test_score'].plot(yerr=[results['std_test_score'], results['std_test_score']], subplots=True)\n",
        "plt.ylabel('Mean ROC_AUC')\n",
        "plt.xlabel('Hyperparameter space')"
      ],
      "metadata": {
        "id": "v6avyzSWsizl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Opciones de Cross Validation -> Esto se inserta en el hiperparámetro cv\n",
        "# K-Fold Cross-Validation\n",
        "#kf = KFold(n_splits=5, shuffle=True, random_state=4)\n",
        "# Repeated K-Fold Cross-Validation\n",
        "#rkf = RepeatedKFold(n_splits=5, n_repeats=10,random_state=4)\n",
        "# Leave One Out Cross-Validation\n",
        "#loo = LeaveOneOut()\n",
        "# Leave P Out Cross-Validation\n",
        "#lpo = LeavePOut(p=2)\n",
        "# Stratified K Fold Cross-Validation\n",
        "#skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)"
      ],
      "metadata": {
        "id": "-G8pMiCXFZSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Veamos el RandomSearch para encontrar la mejor combinación en el Random Forest"
      ],
      "metadata": {
        "id": "5DzuH29ahpu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up the model\n",
        "rf = RandomForestClassifier(random_state=39)\n",
        "# hyperparameter space\n",
        "rf_param_grid = dict(\n",
        "    n_estimators=stats.randint(10, 200),\n",
        "    min_samples_split=stats.uniform(0, 1),\n",
        "    max_depth=stats.randint(1, 5),\n",
        "    )\n",
        "# search\n",
        "reg_rf = RandomizedSearchCV(rf, rf_param_grid, scoring='roc_auc', cv=5, return_train_score=True, n_iter = 60, random_state=10, n_jobs=4)\n",
        "search_rf = reg_rf.fit(pd.concat([X_train_woe_enc,X_train_t_numoutscal],axis=1), y_train)\n",
        "\n",
        "# best hyperparameters\n",
        "search_rf.best_params_"
      ],
      "metadata": {
        "id": "mkllp9NJg2N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(search_rf.cv_results_)[['params', 'mean_train_score', 'std_train_score','mean_test_score', 'std_test_score']]\n",
        "results.sort_values(by='mean_test_score', ascending=False, inplace=True)\n",
        "results.reset_index(drop=True, inplace=True)\n",
        "results"
      ],
      "metadata": {
        "id": "SxQk8OSWiuic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['mean_train_score'].plot(yerr=[results['std_train_score'], results['std_train_score']], subplots=True)\n",
        "results['mean_test_score'].plot(yerr=[results['std_test_score'], results['std_test_score']], subplots=True)\n",
        "plt.ylabel('Mean ROC_AUC')\n",
        "plt.xlabel('Hyperparameter space')"
      ],
      "metadata": {
        "id": "x0zvAG-riufz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CONCLUSION RF: Evaluemos como le va al modelo con los hiperparametros elegidos en train y test"
      ],
      "metadata": {
        "id": "Sl2_RLXXoNPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lo dejamos entrenado con los parámetros hallados\n",
        "rf = RandomForestClassifier(max_depth= 4, min_samples_split=0.07685550174624711, n_estimators=155, random_state=39)\n",
        "rf.fit(pd.concat([X_train_woe_enc,X_train_t_numoutscal],axis=1), y_train)\n",
        "pred_train_rf = rf.predict_proba(pd.concat([X_train_woe_enc,X_train_t_numoutscal],axis=1))\n",
        "pred_test_rf = rf.predict_proba(pd.concat([X_test_woe_enc,X_test_t_numoutscal],axis=1))\n",
        "print('Train roc_auc: ', roc_auc_score(y_train, pred_train_rf[:,1]))\n",
        "print('Test roc_auc: ', roc_auc_score(y_test, pred_test_rf[:,1]))"
      ],
      "metadata": {
        "id": "1Vp23plJnEjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Gradient Boosting**\n"
      ],
      "metadata": {
        "id": "3yYhNsOaI1TR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluemos la sensibilidad de cada parámetro"
      ],
      "metadata": {
        "id": "Eb8Lo6hOJMG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nro de Arboles"
      ],
      "metadata": {
        "id": "cFxyJMFrJPjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up the model\n",
        "gbc = GradientBoostingClassifier(random_state=0)\n",
        "\n",
        "# determine the hyperparameter space\n",
        "gbc_param_grid = dict(\n",
        "    n_estimators=[10, 20, 50, 100, 200],\n",
        "    #min_samples_split=[0.01, 0.05, 0.1, 0.2, 0.3, 0.5],\n",
        "    #max_depth=[1,2,3,4,5],\n",
        "    )\n",
        "\n",
        "# search\n",
        "reg = GridSearchCV(gbc, gbc_param_grid, scoring='roc_auc', return_train_score=True, cv=5, n_jobs=4)\n",
        "search = reg.fit(pd.concat([X_train_woe_enc,X_train_t_numoutscal],axis=1), y_train)\n",
        "\n",
        "# best hyperparameters\n",
        "search.best_params_"
      ],
      "metadata": {
        "id": "99ap-8YQAETp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(search.cv_results_)[['params', 'mean_train_score', 'std_train_score', 'mean_test_score', 'std_test_score']]\n",
        "results"
      ],
      "metadata": {
        "id": "4dVVE4MCAEMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot results\n",
        "results.index = gbc_param_grid['n_estimators']\n",
        "results['mean_train_score'].plot(yerr=[results['std_train_score'], results['std_train_score']], subplots=True)\n",
        "results['mean_test_score'].plot(yerr=[results['std_test_score'], results['std_test_score']], subplots=True)\n",
        "plt.ylim(0.6, 1)\n",
        "plt.ylabel('roc_auc')\n",
        "plt.xlabel('n_estimators')"
      ],
      "metadata": {
        "id": "HxGPowJfAEJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nro mínimo de observaciones para partir el nodo"
      ],
      "metadata": {
        "id": "py7K-d_QM9Se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up the model\n",
        "gbc = GradientBoostingClassifier(random_state=0)\n",
        "\n",
        "# determine the hyperparameter space\n",
        "gbc_param_grid = dict(\n",
        "    #n_estimators=[10, 20, 50, 100, 200],\n",
        "    min_samples_split=[0.01, 0.05, 0.1, 0.2, 0.3, 0.5],\n",
        "    #max_depth=[1,2,3,4,5],\n",
        "    )\n",
        "\n",
        "# search\n",
        "reg = GridSearchCV(gbc, gbc_param_grid, scoring='roc_auc', return_train_score=True, cv=5, n_jobs=4)\n",
        "search = reg.fit(pd.concat([X_train_woe_enc,X_train_t_numoutscal],axis=1), y_train)\n",
        "\n",
        "# best hyperparameters\n",
        "search.best_params_"
      ],
      "metadata": {
        "id": "fnbETvRmAEF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(search.cv_results_)[['params', 'mean_train_score', 'std_train_score', 'mean_test_score', 'std_test_score']]\n",
        "results"
      ],
      "metadata": {
        "id": "CLX-QgTJAEDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot results\n",
        "results.index = gbc_param_grid['min_samples_split']\n",
        "results['mean_train_score'].plot(yerr=[results['std_train_score'], results['std_train_score']], subplots=True)\n",
        "results['mean_test_score'].plot(yerr=[results['std_test_score'], results['std_test_score']], subplots=True)\n",
        "plt.ylim(0.6, 1)\n",
        "plt.ylabel('roc_auc')\n",
        "plt.xlabel('min_samples_split')"
      ],
      "metadata": {
        "id": "RSohnGg8OwUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Profundidad"
      ],
      "metadata": {
        "id": "mx-KA9VYUQjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up the model\n",
        "gbc = GradientBoostingClassifier(random_state=0)\n",
        "\n",
        "# determine the hyperparameter space\n",
        "gbc_param_grid = dict(\n",
        "    #n_estimators=[10, 20, 50, 100, 200],\n",
        "    #min_samples_split=[0.01, 0.05, 0.1, 0.2, 0.3, 0.5],\n",
        "    max_depth=[1,2,3,4,5],\n",
        "    )\n",
        "\n",
        "# search\n",
        "reg = GridSearchCV(gbc, gbc_param_grid, scoring='roc_auc', return_train_score=True, cv=5, n_jobs=4)\n",
        "search = reg.fit(pd.concat([X_train_woe_enc,X_train_t_numoutscal],axis=1), y_train)\n",
        "\n",
        "# best hyperparameters\n",
        "search.best_params_"
      ],
      "metadata": {
        "id": "Oqv5rOvIOwRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(search.cv_results_)[['params', 'mean_train_score', 'std_train_score', 'mean_test_score', 'std_test_score']]\n",
        "results"
      ],
      "metadata": {
        "id": "RNABQ_kUOwOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot results\n",
        "results.index = gbc_param_grid['max_depth']\n",
        "results['mean_train_score'].plot(yerr=[results['std_train_score'], results['std_train_score']], subplots=True)\n",
        "results['mean_test_score'].plot(yerr=[results['std_test_score'], results['std_test_score']], subplots=True)\n",
        "plt.ylim(0.6, 1)\n",
        "plt.ylabel('roc_auc')\n",
        "plt.xlabel('max_depth')"
      ],
      "metadata": {
        "id": "i2wE6ekaOwL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Veamos al GridSearch con todos los parámetros para evaluar la mejor combinación"
      ],
      "metadata": {
        "id": "gYgJbGLDVGqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up the model\n",
        "gbc = GradientBoostingClassifier(random_state=0)\n",
        "\n",
        "# determine the hyperparameter space\n",
        "gbc_param_grid = dict(\n",
        "    n_estimators=[10, 20, 50, 100, 200],\n",
        "    min_samples_split=[0.01, 0.05, 0.1, 0.2, 0.3, 0.5],\n",
        "    max_depth=[1,2,3,4,5],\n",
        "    )\n",
        "\n",
        "# search\n",
        "reg = GridSearchCV(gbc, gbc_param_grid, scoring='roc_auc', return_train_score=True, cv=5, n_jobs=4)\n",
        "search = reg.fit(pd.concat([X_train_woe_enc,X_train_t_numoutscal],axis=1), y_train)\n",
        "\n",
        "# best hyperparameters\n",
        "search.best_params_"
      ],
      "metadata": {
        "id": "UmrmhCLoUn-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(search.cv_results_)[['params', 'mean_train_score', 'std_train_score','mean_test_score', 'std_test_score']]\n",
        "results.sort_values(by='mean_test_score', ascending=False, inplace=True)\n",
        "results.reset_index(drop=True, inplace=True)\n",
        "results"
      ],
      "metadata": {
        "id": "DdhxzL6XUn0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['mean_train_score'].plot(yerr=[results['std_train_score'], results['std_train_score']], subplots=True)\n",
        "results['mean_test_score'].plot(yerr=[results['std_test_score'], results['std_test_score']], subplots=True)\n",
        "plt.ylabel('Mean ROC_AUC')\n",
        "plt.xlabel('Hyperparameter space')"
      ],
      "metadata": {
        "id": "bkEwJQdpUnw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Veamos el RandomSearch para encontrar la mejor combinación en el Gradient Boosting"
      ],
      "metadata": {
        "id": "EQhBh02pprUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up the model\n",
        "gbc = GradientBoostingClassifier(random_state=0)\n",
        "\n",
        "# determine the hyperparameter space\n",
        "gbc_param_grid = dict(\n",
        "    n_estimators=stats.randint(10, 200),\n",
        "    min_samples_split=stats.uniform(0, 1),\n",
        "    max_depth=stats.randint(1, 5),\n",
        "    )\n",
        "\n",
        "# search\n",
        "reg_gbc = RandomizedSearchCV(gbc, gbc_param_grid, scoring='roc_auc', cv=5, return_train_score=True, n_iter = 60, random_state=10, n_jobs=4)\n",
        "search_gbc = reg_gbc.fit(pd.concat([X_train_woe_enc,X_train_t_numoutscal],axis=1), y_train)\n",
        "\n",
        "# best hyperparameters\n",
        "search_gbc.best_params_"
      ],
      "metadata": {
        "id": "KLKHDgrHX5YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(search_gbc.cv_results_)[['params', 'mean_train_score', 'std_train_score','mean_test_score', 'std_test_score']]\n",
        "results.sort_values(by='mean_test_score', ascending=False, inplace=True)\n",
        "results.reset_index(drop=True, inplace=True)\n",
        "results"
      ],
      "metadata": {
        "id": "zfoL4k3rX5U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['mean_train_score'].plot(yerr=[results['std_train_score'], results['std_train_score']], subplots=True)\n",
        "results['mean_test_score'].plot(yerr=[results['std_test_score'], results['std_test_score']], subplots=True)\n",
        "plt.ylabel('Mean ROC_AUC')\n",
        "plt.xlabel('Hyperparameter space')"
      ],
      "metadata": {
        "id": "AyQLohmhX5SB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CONCLUSION GBC: Evaluemos como le va al modelo con los parámetros elegidos en train y test"
      ],
      "metadata": {
        "id": "qUWkDDwFvo0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lo dejamos entrenado con los parámetros hallados\n",
        "gbc = GradientBoostingClassifier(max_depth= 4, min_samples_split=0.4674032789842478, n_estimators=153, random_state=0)\n",
        "gbc.fit(pd.concat([X_train_woe_enc,X_train_t_numoutscal],axis=1), y_train)\n",
        "pred_train_gbc = gbc.predict_proba(pd.concat([X_train_woe_enc,X_train_t_numoutscal],axis=1))\n",
        "pred_test_gbc = gbc.predict_proba(pd.concat([X_test_woe_enc,X_test_t_numoutscal],axis=1))\n",
        "print('Train roc_auc: ', roc_auc_score(y_train, pred_train_gbc[:,1]))\n",
        "print('Test roc_auc: ', roc_auc_score(y_test, pred_test_gbc[:,1]))"
      ],
      "metadata": {
        "id": "yPVqzLAS4cQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entonces, basado en sus rendimientos en test, cuál es el mejor modelo?"
      ],
      "metadata": {
        "id": "-0yLJk_SytE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Logit Test roc_auc: ', roc_auc_score(y_test, pred_test_logit[:,1]), 'Logit Test GINI: ', 2*roc_auc_score(y_test, pred_test_logit[:,1])-1)\n",
        "print('RF Test roc_auc: ', roc_auc_score(y_test, pred_test_rf[:,1]), 'RF Test GINI: ', 2*roc_auc_score(y_test, pred_test_rf[:,1])-1)\n",
        "print('GBC Test roc_auc: ', roc_auc_score(y_test, pred_test_gbc[:,1]), 'GBC Test GINI: ', 2*roc_auc_score(y_test, pred_test_gbc[:,1])-1)"
      ],
      "metadata": {
        "id": "629zxWoby1co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### FINALMENTE: Si bien no hay una gran diferencia entre los 3 modelos, en cuanto a performance, el GINI más alto es el correspondiente al Modelo de **Gradient Boosting**"
      ],
      "metadata": {
        "id": "kQtsrLrI0Fy0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyFwlqg0UQp_"
      },
      "source": [
        "### **6. Valoración del Modelo**\n",
        "Empecemos a revisar con el modelo final algunas métricas de valoración del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP1NOrLnaRpq"
      },
      "source": [
        "### **Accuracy**\n",
        "Porcentaje de predicciones correctas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIJoRTagbHQ7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epSZ4-AWaTwr"
      },
      "outputs": [],
      "source": [
        "br_test=y_test.value_counts() / len(y_test)\n",
        "br_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaM6gEtNbbFI"
      },
      "outputs": [],
      "source": [
        "y_train_base = pd.Series(np.zeros(len(y_train)))\n",
        "y_test_base = pd.Series(np.zeros(len(y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvI7th76bghY"
      },
      "outputs": [],
      "source": [
        "print('Accuracy Baseline test: ', accuracy_score(y_test, y_test_base))\n",
        "print('Accuracy GBC test:', accuracy_score(y_test, gbc.predict(pd.concat([X_test_woe_enc,X_test_t_numoutscal],axis=1))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uo7P5uvgpV4G"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    #accuracy_score,\n",
        "    balanced_accuracy_score,\n",
        "    recall_score,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Hn67goDpO4x"
      },
      "outputs": [],
      "source": [
        "print('Balanced accuracy, Baseline test: ', balanced_accuracy_score(y_test, y_test_base))\n",
        "print('Balanced accuracy, GBC test:',  balanced_accuracy_score(y_test,gbc.predict(pd.concat([X_test_woe_enc,X_test_t_numoutscal],axis=1))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mexmrjZ-Z6fN"
      },
      "source": [
        "## Precision, Recall, F-measure, Support\n",
        "\n",
        "- **Precision** = tp / (tp + fp)\n",
        "\n",
        "- **Recall** = tp / (tp + fn)\n",
        "\n",
        "- **F1** = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "- **Support** = Number of cases on each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAsXYpdGZCmp"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    precision_recall_fscore_support,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNlBArqrZIqc"
      },
      "outputs": [],
      "source": [
        "# Precision\n",
        "print('Precision Baseline test: ', precision_score(y_test, y_test_base))\n",
        "print('Precision GBC test:', precision_score(y_test,gbc.predict(pd.concat([X_test_woe_enc,X_test_t_numoutscal],axis=1))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_QawKIgZCcL"
      },
      "outputs": [],
      "source": [
        "# Recall\n",
        "print('Recall Baseline test: ', recall_score(y_test, y_test_base))\n",
        "print('Recall GBC test:', recall_score(y_test,gbc.predict(pd.concat([X_test_woe_enc,X_test_t_numoutscal],axis=1))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkboDmWjZIz_"
      },
      "outputs": [],
      "source": [
        "# F1-Score\n",
        "print('F-measure Baseline test: ', f1_score(y_test, y_test_base))\n",
        "print('F-measure GBC test:', f1_score(y_test, gbc.predict(pd.concat([X_test_woe_enc,X_test_t_numoutscal],axis=1))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gS98YKCkZPa"
      },
      "outputs": [],
      "source": [
        "precision, recall, fscore, support = precision_recall_fscore_support(\n",
        "    y_test, gbc.predict(pd.concat([X_test_woe_enc,X_test_t_numoutscal],axis=1)))\n",
        "\n",
        "print('Precision: ', precision)\n",
        "print('Recall: ', recall)\n",
        "print('F1-score: ', fscore)\n",
        "print('Support: ', support)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhsyybO2tzyT"
      },
      "outputs": [],
      "source": [
        "X_train_woe_enc_tot=pd.concat([X_train_woe_enc,X_train_t_numoutscal],axis=1)\n",
        "X_test_woe_enc_tot=pd.concat([X_test_woe_enc,X_test_t_numoutscal],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4b2goxguEBO"
      },
      "outputs": [],
      "source": [
        "X_train_woe_enc_tot.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umPulklmuH_X"
      },
      "outputs": [],
      "source": [
        "X_test_woe_enc_tot.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs4jnJxVoJG9"
      },
      "source": [
        "## Matriz de Confusión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDKAvqpGoB65"
      },
      "source": [
        "TN | FP\n",
        "\n",
        "FN | TP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoRfLharm3xx"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9REvS0Em5yB"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(y_test, y_test_base, labels=[0,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A62MpuDoVz6"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(y_test, gbc.predict(X_test_woe_enc_tot), labels=[0,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENGOTnl4ZL5L"
      },
      "source": [
        "## Identificamos un punto de corte óptimo que maximice el F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCC2q1gC0r7G"
      },
      "outputs": [],
      "source": [
        "from yellowbrick.classifier import (\n",
        "    DiscriminationThreshold,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4vrK_bWoVvO"
      },
      "outputs": [],
      "source": [
        "visualizer = DiscriminationThreshold(gbc, is_fitted=True, random_state=0, argmax='fscore')#fbeta=3\n",
        "visualizer.fit(X_test_woe_enc_tot, y_test)\n",
        "visualizer.score(X_test_woe_enc_tot, y_test)\n",
        "visualizer.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u71irvyZUTC"
      },
      "source": [
        "### Adicionamos un cálculo de ROC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8MvGF1l0tmL"
      },
      "outputs": [],
      "source": [
        "from yellowbrick.classifier import ROCAUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKAHcFA1NguF"
      },
      "outputs": [],
      "source": [
        "visualizer2 = ROCAUC(gbc, is_fitted=True, micro=False, macro=False,)\n",
        "visualizer2.fit(X_test_woe_enc_tot, y_test)\n",
        "visualizer2.score(X_test_woe_enc_tot, y_test)\n",
        "visualizer2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F99pmyHZe6l"
      },
      "source": [
        "### 7. Técnicas de balanceo\n",
        "En este punto, propongamos algunos métodos de balanceo y revisemos su impacto en el performance del modelo candidato"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install imbalanced-learn"
      ],
      "metadata": {
        "id": "uv1OhTsRQt_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvVBCmNSbCFR"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1fX6kT9egFZ"
      },
      "source": [
        "#### Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lc_Knvj50trV"
      },
      "outputs": [],
      "source": [
        "rus = RandomUnderSampler(\n",
        "    sampling_strategy='auto',\n",
        "    random_state=0,\n",
        "    replacement=True\n",
        ")\n",
        "X_train_woe_enc_tot_rus, y_train_rus = rus.fit_resample(X_train_woe_enc_tot, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up the model\n",
        "gbc2 = GradientBoostingClassifier(random_state=0)\n",
        "\n",
        "# determine the hyperparameter space\n",
        "gbc_param_grid = dict(\n",
        "    n_estimators=stats.randint(10, 200),\n",
        "    min_samples_split=stats.uniform(0, 1),\n",
        "    max_depth=stats.randint(1, 5),\n",
        "    )\n",
        "\n",
        "# search\n",
        "reg_gbc2 = RandomizedSearchCV(gbc2, gbc_param_grid, scoring='roc_auc', cv=5, return_train_score=True, n_iter = 60, random_state=10, n_jobs=4)\n",
        "search_gbc2 = reg_gbc2.fit(X_train_woe_enc_tot_rus, y_train_rus)\n",
        "\n",
        "# best hyperparameters\n",
        "search_gbc2.best_params_"
      ],
      "metadata": {
        "id": "QGatAez3AF1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(search_gbc2.cv_results_)[['params', 'mean_train_score', 'std_train_score','mean_test_score', 'std_test_score']]\n",
        "results.sort_values(by='mean_test_score', ascending=False, inplace=True)\n",
        "results.reset_index(drop=True, inplace=True)\n",
        "results"
      ],
      "metadata": {
        "id": "oNoGmtHSAFat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['mean_train_score'].plot(yerr=[results['std_train_score'], results['std_train_score']], subplots=True)\n",
        "results['mean_test_score'].plot(yerr=[results['std_test_score'], results['std_test_score']], subplots=True)\n",
        "plt.ylabel('Mean ROC_AUC')\n",
        "plt.xlabel('Hyperparameter space')"
      ],
      "metadata": {
        "id": "n_n6g3npCA2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo GBC con Balanceo\n",
        "pred_train_gbc2 = search_gbc2.predict_proba(X_train_woe_enc_tot)\n",
        "pred_test_gbc2 = search_gbc2.predict_proba(X_test_woe_enc_tot)\n",
        "print('Train roc_auc: ', roc_auc_score(y_train, pred_train_gbc2[:,1]), 'GINI Train ', 2*roc_auc_score(y_train, pred_train_gbc2[:,1])-1)\n",
        "print('Test roc_auc: ', roc_auc_score(y_test, pred_test_gbc2[:,1]), 'GINI Test ', 2*roc_auc_score(y_test, pred_test_gbc2[:,1])-1)"
      ],
      "metadata": {
        "id": "du_yV3qKCAzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo GBC Previo\n",
        "pred_train_gbc = search_gbc.predict_proba(X_train_woe_enc_tot)\n",
        "pred_test_gbc = search_gbc.predict_proba(X_test_woe_enc_tot)\n",
        "print('Train roc_auc: ', roc_auc_score(y_train, pred_train_gbc[:,1]), 'GINI Train ', 2*roc_auc_score(y_train, pred_train_gbc[:,1])-1)\n",
        "print('Test roc_auc: ', roc_auc_score(y_test, pred_test_gbc[:,1]), 'GINI Test ', 2*roc_auc_score(y_test, pred_test_gbc[:,1])-1)"
      ],
      "metadata": {
        "id": "HvPJN3jrCAwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Calibración del Modelo:\n",
        "En esta parte verificaremos, y de ser necesario, calibraremos el modelo revisando la relación entre los valores los ratios de default reales y las PDs promedios que arroja el modelo."
      ],
      "metadata": {
        "id": "pxrRe-Q5naph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.calibration import calibration_curve"
      ],
      "metadata": {
        "id": "wa6Id-KgnaJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Veamos los RDs y los promedios de PDs en cada bucket para el modelo original (sin balanceo)\n",
        "fraction_of_positives, mean_predicted_value = calibration_curve(\n",
        "    y_test, pred_test_gbc[:, 1], n_bins=10, strategy='uniform')\n",
        "\n",
        "len(mean_predicted_value), len(fraction_of_positives)"
      ],
      "metadata": {
        "id": "utMFKX0as24t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_predicted_value"
      ],
      "metadata": {
        "id": "MANuM1ymu0lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraction_of_positives"
      ],
      "metadata": {
        "id": "4Qwn-A8Bs21D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Una función para consolidar lo anterior\n",
        "def plot_calibration_curve(y_true, probs, bins, strategy):\n",
        "\n",
        "    fraction_of_positives, mean_predicted_value = calibration_curve(\n",
        "        y_true, probs, n_bins=bins, strategy=strategy)\n",
        "\n",
        "    max_val = max(mean_predicted_value)\n",
        "\n",
        "    plt.figure(figsize=(8,10))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(mean_predicted_value, fraction_of_positives, label='Logistic Regression')\n",
        "    plt.plot(np.linspace(0, max_val, bins), np.linspace(0, max_val, bins),\n",
        "         linestyle='--', color='red', label='Perfect calibration')\n",
        "\n",
        "    plt.xlabel('Probability Predictions')\n",
        "    plt.ylabel('Fraction of positive examples')\n",
        "    plt.title('Calibration Curve')\n",
        "    plt.legend(loc='upper left')\n",
        "\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.hist(probs, range=(0, 1), bins=bins, density=True, stacked=True, alpha=0.3)\n",
        "    plt.xlabel('Probability Predictions')\n",
        "    plt.ylabel('Fraction of examples')\n",
        "    plt.title('Density')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qmAMdI0Rwh20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo Original, sin balanceo\n",
        "plot_calibration_curve(y_test, pred_test_gbc[:, 1], bins=10, strategy='uniform')"
      ],
      "metadata": {
        "id": "3jhHYABYwhzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import brier_score_loss"
      ],
      "metadata": {
        "id": "XrgIfsXJJo9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brier_score_loss(y_test, pred_test_gbc[:, 1])"
      ],
      "metadata": {
        "id": "uhVNCbvLJsPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo con Undersampling\n",
        "plot_calibration_curve(y_test, pred_test_gbc2[:, 1], bins=10, strategy='uniform')"
      ],
      "metadata": {
        "id": "oPguaKYkwhQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brier_score_loss(y_test, pred_test_gbc2[:, 1])"
      ],
      "metadata": {
        "id": "QPSkn0aAKAN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Planteemos dos métodos, el ajuste por función sigmoide y el ajuste por función isotónica"
      ],
      "metadata": {
        "id": "rVF1LA1V7cOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.calibration import CalibratedClassifierCV"
      ],
      "metadata": {
        "id": "O0EnRNQG3wmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sobre el modelo original\n",
        "# Calibración Sigmoide\n",
        "cal_sigmoid = CalibratedClassifierCV(search_gbc, cv='prefit', method='sigmoid')\n",
        "cal_sigmoid.fit(X_test_woe_enc_tot, y_test)\n",
        "prob_sigmoid = cal_sigmoid.predict_proba(X_test_woe_enc_tot)[:, 1]\n",
        "\n",
        "# Calibración Isotónica\n",
        "cal_isotonic = CalibratedClassifierCV(search_gbc, cv='prefit', method='isotonic')\n",
        "cal_isotonic.fit(X_test_woe_enc_tot, y_test)\n",
        "prob_isotonic = cal_isotonic.predict_proba(X_test_woe_enc_tot)[:, 1]"
      ],
      "metadata": {
        "id": "Gbrkew2g3meZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Revisemos la calibración Sigmoide"
      ],
      "metadata": {
        "id": "6ehctH_5_PDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_calibration_curve(y_test, prob_sigmoid, bins=10, strategy='uniform')"
      ],
      "metadata": {
        "id": "iflEyvUd5Bo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Acaso la calibración varía la discriminación del modelo?"
      ],
      "metadata": {
        "id": "WDoa0YJU-UuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test set')\n",
        "print('GBC roc-auc: {}'.format(roc_auc_score(y_test, pred_test_gbc[:,1])))\n",
        "print('Test set con Calibrado')\n",
        "print('GBC roc-auc: {}'.format(roc_auc_score(y_test, prob_sigmoid)))"
      ],
      "metadata": {
        "id": "SD6UfuRT-TmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test set')\n",
        "print('Brier Score: {}'.format(brier_score_loss(y_test, pred_test_gbc[:, 1])))\n",
        "print('Test set con Calibrado')\n",
        "print('Brier Score: {}'.format(brier_score_loss(y_test, prob_sigmoid)))"
      ],
      "metadata": {
        "id": "ORzXYRiMKOB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ahora revisemos la calibración isotónica"
      ],
      "metadata": {
        "id": "uiu6o_Q9_Wah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_calibration_curve(y_test, prob_isotonic, bins=10, strategy='uniform')"
      ],
      "metadata": {
        "id": "679ku4_c4rvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test set')\n",
        "print('GBC roc-auc: {}'.format(roc_auc_score(y_test, pred_test_gbc[:,1])))\n",
        "print('Test set con Calibrado')\n",
        "print('GBC roc-auc: {}'.format(roc_auc_score(y_test, prob_isotonic)))"
      ],
      "metadata": {
        "id": "zkrtNaP-_L4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test set')\n",
        "print('Brier Score: {}'.format(brier_score_loss(y_test, pred_test_gbc[:, 1])))\n",
        "print('Test set con Calibrado')\n",
        "print('Brier Score: {}'.format(brier_score_loss(y_test, prob_isotonic)))"
      ],
      "metadata": {
        "id": "5lGHqbIlLCYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sobre el modelo balanceado por undersampling\n",
        "# Calibración Sigmoide\n",
        "cal_sigmoid2 = CalibratedClassifierCV(search_gbc2, cv='prefit', method='sigmoid')\n",
        "cal_sigmoid2.fit(X_test_woe_enc_tot, y_test)\n",
        "prob_sigmoid2 = cal_sigmoid2.predict_proba(X_test_woe_enc_tot)[:, 1]\n",
        "\n",
        "# Calibración Isotónica\n",
        "cal_isotonic2 = CalibratedClassifierCV(search_gbc2, cv='prefit', method='isotonic')\n",
        "cal_isotonic2.fit(X_test_woe_enc_tot, y_test)\n",
        "prob_isotonic2 = cal_isotonic2.predict_proba(X_test_woe_enc_tot)[:, 1]"
      ],
      "metadata": {
        "id": "uSU7rC1NEwos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calibración sigmoidea\n",
        "plot_calibration_curve(y_test, prob_sigmoid2, bins=10, strategy='uniform')"
      ],
      "metadata": {
        "id": "Tz5i64OWFQFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test set')\n",
        "print('GBC roc-auc: {}'.format(roc_auc_score(y_test, pred_test_gbc2[:,1])))\n",
        "print('Test set con Calibrado')\n",
        "print('GBC roc-auc: {}'.format(roc_auc_score(y_test, prob_sigmoid2)))"
      ],
      "metadata": {
        "id": "Ecba6vgaGkUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test set')\n",
        "print('Brier Score: {}'.format(brier_score_loss(y_test, pred_test_gbc2[:, 1])))\n",
        "print('Test set con Calibrado')\n",
        "print('Brier Score: {}'.format(brier_score_loss(y_test, prob_sigmoid2)))"
      ],
      "metadata": {
        "id": "8FsQHmrqLLvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calibración isotónica\n",
        "plot_calibration_curve(y_test, prob_isotonic2, bins=10, strategy='uniform')"
      ],
      "metadata": {
        "id": "89K134WnF1wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test set')\n",
        "print('GBC roc-auc: {}'.format(roc_auc_score(y_test, pred_test_gbc2[:,1])))\n",
        "print('Test set con Calibrado')\n",
        "print('GBC roc-auc: {}'.format(roc_auc_score(y_test, prob_isotonic2)))"
      ],
      "metadata": {
        "id": "BUEYh08HH6PF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test set')\n",
        "print('Brier Score: {}'.format(brier_score_loss(y_test, pred_test_gbc2[:, 1])))\n",
        "print('Test set con Calibrado')\n",
        "print('Brier Score: {}'.format(brier_score_loss(y_test, prob_isotonic2)))"
      ],
      "metadata": {
        "id": "AFhvBdC5LnrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9. Unboxing de Modelos**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kHAotKtYxM_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Primero, entendamos la importancia de cada variable. Hagamos el ejercicio con cada tipo de algoritmo"
      ],
      "metadata": {
        "id": "MYwOCWbNHM2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Logit**"
      ],
      "metadata": {
        "id": "m2k-BDn-NJ_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fi=pd.Series(logit.coef_[0],index=logit.feature_names_in_)\n",
        "fi.sort_values(ascending=True, inplace=True)\n",
        "fi.plot.barh(color='blue')\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show ()"
      ],
      "metadata": {
        "id": "F02TeRdnKazd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Random Forest**"
      ],
      "metadata": {
        "id": "RmMHGTLVNOhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fi=pd.Series(rf.feature_importances_,index=rf.feature_names_in_)\n",
        "fi.sort_values(ascending=True, inplace=True)\n",
        "fi.plot.barh(color='blue')\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show ()"
      ],
      "metadata": {
        "id": "2l9XnysNBivB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Gradient Boosting**"
      ],
      "metadata": {
        "id": "h1bqGOiJNc_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fi=pd.Series(gbc.feature_importances_,index=gbc.feature_names_in_)\n",
        "fi.sort_values(ascending=True, inplace=True)\n",
        "fi.plot.barh(color='blue')\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show ()"
      ],
      "metadata": {
        "id": "QQVq6Na5Nd9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ahora realicemos un análisis de la importancia de las variables usando **SHAP**"
      ],
      "metadata": {
        "id": "MzNGhxXDNuMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap"
      ],
      "metadata": {
        "id": "TFSNo_VNzrhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap"
      ],
      "metadata": {
        "id": "AUCprGhY4N30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.Explainer(gbc)\n",
        "shap_values_bin = explainer(X_test_woe_enc_tot)\n",
        "print(shap_values_bin.shape)"
      ],
      "metadata": {
        "id": "KG1sX7XkxZ9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.waterfall(shap_values_bin[0],max_display=30)"
      ],
      "metadata": {
        "id": "didf3IpTPTOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### En este punto hagamos la prueba de como se incrementa o reduce el riesgo según el aprote de cada variable"
      ],
      "metadata": {
        "id": "yBatBHtVlrfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test_gbc[0,1]"
      ],
      "metadata": {
        "id": "w6tCnM4_dZ5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "vIw4bN50HG_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# el valor del log odds en la primera observación es\n",
        "x=-3.461\n",
        "# Por tanto su probabilidad es:\n",
        "1/(1+math.exp(-x))"
      ],
      "metadata": {
        "id": "pNWa_OpMgg5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Podemos graficar la relación entre los shap values (log odds) y los valores de una variable"
      ],
      "metadata": {
        "id": "v-iZ1bJyngSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.scatter(shap_values_bin[:, \"EDAD_T\"])"
      ],
      "metadata": {
        "id": "KvLRsxxkqNws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.scatter(shap_values_bin[:, \"INGRESO_CLIENTE\"])"
      ],
      "metadata": {
        "id": "hgWGxpdZm5YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En este punto revisamos el valor en probabilidad y como se explica cada punto\n",
        "shap.initjs()\n",
        "shap.plots.force(shap_values_bin[0],link='logit')"
      ],
      "metadata": {
        "id": "Mn2IQsv3QMRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Con el gráfico de barras vamos a evaluar la importancia media de cada variable"
      ],
      "metadata": {
        "id": "ufJEvB6ysBn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.bar(shap_values_bin,max_display=30)"
      ],
      "metadata": {
        "id": "HOyiS_dbQMOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Podemos también construir un gráfico local, es decir, para una observación"
      ],
      "metadata": {
        "id": "m5xv9J12r-Xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.bar(shap_values_bin[0],max_display=30)"
      ],
      "metadata": {
        "id": "Gv9ihnysry3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Este tipo de gráfico evalua todo el conjunto\n",
        "shap.plots.beeswarm(shap_values_bin, max_display=30)"
      ],
      "metadata": {
        "id": "eRRJ0UBpQML2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10. Pickling y Unpickling el Modelo y del Pipeline del Feature Engineering**"
      ],
      "metadata": {
        "id": "hWaro-Sivfm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "RMZ7QlSFvfI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Empaquetamos el pipeline del feature engineering\n",
        "with open('fe_pipeline.pickle','wb') as fe_data_file:\n",
        "     pickle.dump(pipe_5,fe_data_file)"
      ],
      "metadata": {
        "id": "QfCgCgOOijMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Empaquetamos el modelo obtenido\n",
        "with open('final_model.pickle','wb') as modelFile:\n",
        "     pickle.dump(gbc,modelFile)"
      ],
      "metadata": {
        "id": "eHAimfYPxvSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el pipeline del feature engineering\n",
        "with open('fe_pipeline.pickle','rb') as fe_data_file:\n",
        "     fe_final = pickle.load(fe_data_file)"
      ],
      "metadata": {
        "id": "Ji2-Ja2ejqsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el modelo\n",
        "with open('final_model.pickle','rb') as modelFile:\n",
        "     modelo_final = pickle.load(modelFile)"
      ],
      "metadata": {
        "id": "SB9CdtZ2wQX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Probemos el pipeline\n",
        "X_train_t_p=fe_final.transform(X_train)\n",
        "X_test_t_p=fe_final.transform(X_test)"
      ],
      "metadata": {
        "id": "11IMqVQ9kKCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_woe_enc_tot_p=pd.concat([X_train_t_p[cat_cols_2],X_train_t_p[num_cols_2]],axis=1)\n",
        "X_test_woe_enc_tot_p=pd.concat([X_test_t_p[cat_cols_2],X_test_t_p[num_cols_2]],axis=1)"
      ],
      "metadata": {
        "id": "_yZSHYeLlHah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probemos el modelo\n",
        "pred_train_prueba = modelo_final.predict_proba(X_train_woe_enc_tot_p)\n",
        "pred_test_prueba = modelo_final.predict_proba(X_test_woe_enc_tot_p)\n",
        "print('GBC Train Prueba roc-auc: {}'.format(roc_auc_score(y_train, pred_train_prueba[:,1])))\n",
        "print('GBC Test Prueba roc-auc: {}'.format(roc_auc_score(y_test, pred_test_prueba[:,1])))"
      ],
      "metadata": {
        "id": "YKXYaCvsyKqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([X_test,y_test],axis=1).to_csv('Base_SolicitudesCreditoEfectivo_Test.csv', index = False)"
      ],
      "metadata": {
        "id": "yY4Em4J1oz5Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}